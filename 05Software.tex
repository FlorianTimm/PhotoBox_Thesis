\documentclass[./00PhotoBox.tex]{subfiles}
\graphicspath{{\subfix{./img/}}}
\begin{document}
\renewcommand{\itemautorefname}{Anforderung}

\chapter{Software-Entwicklung}
\label{c:software}

\todo{UML-Diagramme reparieren}
Für die Steuerung der Kameras und die anschließende Berechnung des 3D-Modelles muss eine Steuerungssoftware für das Kamerasystem und eine entsprechende Schnittstelle zu einer SfM-Software geschaffen werden. Diese Entwicklung erfolgte hauptsächlich in Python in Form von Prototyping. Das Kapitel beschreibt die Anforderungen an die Software (\autoref{sec:Anforderungsanalyse}) und die zu implementierenden Anwendungsfälle (\autoref{sec:Anwendungsfallmodellierung}). Abschließend wird die Implementation (\autoref{sec:Implementierung}) erarbeitet.
\todo{Erst Anwendungsfälle, dann Anforderungen?}

\section{Anforderungsanalyse}
\label{sec:Anforderungsanalyse}

Die notwendigen Anforderungen an das System wurden aus \autoref{c:einleitung} und \ref{c:photogrammetrie} abgeleitet und in diesen Abschnitt in Form eines Lastenheftes aufgezeichnet. Sie wurden in funktionale und nicht-funktionale Anforderungen unterteilt. Die funktionalen Anforderungen beschreiben, was das System leisten soll, die nicht-funktionalen Anforderungen beschreiben, wie das System arbeiten soll. \todo{Quelle Fernuni Hagen?}


\subsection{Funktionale Anforderungen}
\todo{Nummern weiterverwenden}
\begin{enumerate}[label=F\arabic*]
  \item \label{e:zeitgleich} Die Kameras sollen zeitgleich auslösbar sein. Es soll möglichst ver\-zögerungs\-frei ausgelöst werden.
  \item \label{e:button} Die Steuerung soll unabhängig von anderen Geräten möglich sein, beispielsweise per Tastensteuerung.
  \item \label{e:status} Der Status des Systems soll für den Nutzer erkennbar sein - auch ohne Anschluss eines Computers.
  \item \label{e:passpunkte} Es sollen Passpunkte automatisch gefunden und für die Bestimmung der äußeren Orientierung genutzt werden.
  \item \label{e:scharf} Die Bilder sollen scharf und fokussiert sein.
  \item \label{e:licht} Die Belichtung soll automatisch erfolgen, jedoch die Helligkeit der Bilder identisch sein.
\end{enumerate}

\subsection{Schnittstellen}
\todo{Gehören diese zu den funktionellen Anforderungen?}
\begin{enumerate}[label=S\arabic*]
  \item \label{e:intspeicher} Die Daten sollen intern gespeichert werden.
  \item \label{e:usbspeicher} Eine Speicherung auf tragbaren Speichermedien wie USB-Sticks soll möglich sein.
  \item \label{e:sfmsoftware} Eine direkte Übertragung an SfM-Software soll möglich sein.
\end{enumerate}

\subsection{Nicht-funktionale Anforderungen}
\begin{enumerate}[label=N\arabic*]
  \item \label{e:standalone} Die Erfassung soll ohne weitere Hardware möglich sein. Das System soll unabhängig von Netzwerkanschlüssen etc. sein.
  \item \label{e:wlan} Jegliche Kommunikation soll über WLAN erfolgen.
\end{enumerate}

\section{Anwendungsfallmodellierung}
\label{sec:Anwendungsfallmodellierung}

Entsprechend der benötigten Schritte aus \autoref{c:photogrammetrie} und \autoref{img:ablauf} wurden die Anwendungsfälle, die die Benutzeroberfläche ermöglichen soll, im Anwendungsfall-Dia\-gramm in \autoref{img:anwendungsfall} zusammengetragen. Entsprechend der Anforderung einer einfach gehaltenen Bedienung des Systems, ist die Anzahl der verschiedenen Anwendungsfälle gering.

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{./img/uml/uml_usecases.pdf}
  \caption{Anwendungsfall-Diagramm} %Bildunterschrift
  \label{img:anwendungsfall} %ID fürs Bild
\end{figure}

\section{Domänenmodell}

Aus den benötigten Daten wurde das Domänen-Klassendiagramm aus \autoref{img:dokladia} erzeugt. Dieses zeigt vor allem die Abhängigkeiten der einzelnen Datensätze untereinander. Es bildet hiermit die Grundlage für die Datenschnittstellen der einzelnen Komponenten zueinander und den jeweils benötigten Datensätzen.

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{./img/uml/uml_domain.pdf}
  \caption{Domänen-Klassendiagramm} %Bildunterschrift
  \label{img:dokladia} %ID fürs Bild
\end{figure}

\section{Implementierung}
\label{sec:Implementierung}


Die Programmierung des Systems erfolgte iterativ. Einzelne Arbeitspakete wurden in einem Jupyter-Notebook ausprobiert und dann, wenn dieser Schritt erfolgreich war, in den Gesamtworkflow integriert - teilweise sind diese im \autoref{c:voruntersuchungen} beschrieben. Größtenteils wurde der Python-Code objektorientiert und typisiert geschrieben. Die Teile, die auf einem Desktoprechner ausgeführt werden sollen, wurden in Java geschrieben, da hier später die Einrichtung auf verschiedenen Rechnern und Plattformen einfacher ist.

\subsection{Programmablauf}
Die Kommunikation innerhalb des Systems ist in dem Ablaufdiagramm in \autoref{img:uml_sequence_capture} dargestellt. Die Auslösung der Kamera erfolgt über den Software-Button in der Desktop-Software, dem Webinterface oder über einen Taster. Optional werden die Belichtungen der Kameras synchronisiert und anschließend die Aufnahmen erzeugt. Die Raspberry Pi Zero W senden die Aufnahmen und die gefundenen Aruco-Marker an den Raspberry Pi 4. Dieser berechnet die Kamerapositionen und speichert die Daten. Die Desktop-Software kann die Daten dann herunterladen und an die SfM-Software übergeben. Diese erzeugt dann das 3D-Modell. Auf die Details der einzelnen Module wird in den folgenden Abschnitten eingegangen.


\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{./img/uml/uml_sequence_capture.pdf}
  \caption{Ablaufdiagramm zur Kommunikation bei der Aufnahme eines 3D-Modelles} %Bildunterschrift
  \label{img:uml_sequence_capture} %ID fürs Bild
\end{figure}


\subsection{Module auf den Raspberry Pi (Python)}
Die Software auf den Raspberry Pi wurde in Python geschrieben. Hierbei wurde darauf geachtet, dass die Module möglichst unabhängig voneinander sind und nur über definierte Schnittstellen kommunizieren.

\subsubsection{Bibliotheken}
Es wurde, wenn möglich, auf fertige Python-Bibliotheken zurückgegriffen. Hierdurch sollte der Programmieraufwand verringert und auf bereits getesteten Code gesetzt werden. Außerdem greifen viele der Bibliotheken wie OpenCV oder NumPy auf hardwarenahe Berechnungen zurück, sodass der Geschwindigkeitsnachteil von Python nicht weiter ins Gewicht fällt. Die wichtigsten Bibliotheken sind:

\paragraph{OpenCV}
ist eine Bibliothek für Bildbearbeitung und maschinelles Sehen. Sie ist weit verbreitet und bietet viele photogrammetrische Funktionen. Hiermit wurde beispielsweise die Detektion von Markern durchgeführt und die Näherungswerte der Kameras berechnet.

\paragraph{NumPy}
bietet neben vielen weiteren Funktionen die Möglichkeit der Matrizenrechnung. Diese wurde für viele Berechnungen benötigt, beispielsweise für die Berechnungen der Kamera-Projektionen.

\paragraph{SciPy}
wurde für die Berechnung der Bündelblockausgleichung verwendet. Der manuelle Ansatz mit Formeln aus \cite{luhmann} unter Nutzung von NumPy war sehr ressourcenlastig. Unter Verwendung von SciPy und der Projektionsgleichung konnte die Berechnungsdauer stark dezimiert werden.

\paragraph{Flask}
wurde genutzt um die Weboberfläche und die Datendownloads bereitzustellen. Hiermit wurde ein Webserver aufgesetzt, der die Daten der Kameras anzeigt und die Steuerung ermöglicht.

\paragraph{rpi-ws281x}
\label{p:ws281x}
ermöglicht die Steuerung der RGB-LEDs. Hierzu wird das in \cite{ws2811} beschriebene Steuerprotokoll von der Bibliothek implementiert. Die Steuerung kann dann mittels einfacher Farbcodes erfolgen.

\subsubsection{Allgemeine Module}
Es wurden einige Klassen erstellt, die in allen Modulen genutzt wurden. Diese sind in \autoref{img:uml_common} dargestellt. Diese steuern allgemeine Funktionen wie das Logging und das Auslesen der Konfiguration. Außerdem legen die Interfaces die Struktur der Datenübertragung zwischen den Raspberry Pi fest. Die Klasse \texttt{Config} liest die Konfiguration aus einer Datei aus und stellt diese zur Verfügung. Die Klasse \texttt{Logger} ermöglicht das Loggen von Informationen und Fehlern. \texttt{Interface} stellt die Schnittstelle zur Kommunikation mit anderen Modulen bereit. Die Klassen \texttt{CamSettings} und \texttt{ArucoMarkerPos} sind Datenklassen, die die Einstellungen der Kameras und die Position der ArUco-Marker speichern. Diese Daten werden zwischen den Komponenten ausgetauscht -- hierdurch wird sichergestellt, dass das erwartete Datenmodell auf beiden Seiten gleich ist.

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{./img/uml/uml_common_classdiagramm.pdf}
  \caption{Klassen des Common-Package} %Bildunterschrift
  \label{img:uml_common} %ID fürs Bild
\end{figure}


\subsubsection{Master-Steuerung}

Auf einem Raspberry Pi 4 läuft die Gesamt\-steuerung des Systems. Dieses stellt Schnitt\-stellen zur Steuerung auf drei verschiedenen Wegen bereit: per Taster, per Weboberfläche und per Socket-Verbindung\todo{Erklären}. Außerdem stellt es die Daten per REST-Schnittstelle \todo{REST erläutern} zur Verfügung. Die Klassen sind in \autoref{img:master} dargestellt.

Das Skript \texttt{Master} wird automatisch bei Systemstart über \texttt{systemd} als Daemon -- als im Hintergrund und dauerhaft laufender Service (\citep[S. 369]{negus2020linux}) -- gestartet . Hier ist die Webschnittstelle implementiert. Sie ermöglicht die komplette Steuerung, das Konfigurieren sowie das Anzeigen und Herunterladen der Bilder. Das Skript instanziert außerdem die Klasse \texttt{Control}, welche die hauptsächliche Steuerung übernimmt und den Kern des Systems darstellt.

Die Steuerung per Taster implementiert die Klasse \texttt{ButtonControl}. Sie ermöglicht einfache Aufgaben wie das Suchen von Kameras, das Aufnehmen von Bilder und die Aktivierung des Standbys bzw. das Herunterfahren des Systems auch ohne PC durchzuführen (\autoref{e:button}). Die Klasse \texttt{DesktopControlThread} startet, wie der Name bereits vermuten lässt, als eigenständiger Thread und stellt eine Socket-Verbindung zur Kommunikation mit der Desktop-Software und die Steuerung hierüber bereit. Ein weiteren Thread stellt \texttt{CameraControlThread} zur Verfügung. Dieser überwacht das Netzwerk auf Nachrichten der Kameras und initiert die entsprechenden Schritte. Die eigentlichen Verarbeitungsschritte werden in der Klasse \texttt{Control} durchgeführt. Auch für diese Aufgaben werden zum Teil eigene Threads gestartet, damit die Verarbeitung parallel erfolgen kann. Beispielsweise wird der Download der Bilder und die Berechnung von Kamerapositionen in eigenen Threads durchgeführt.

Die \texttt{Control}-Klasse steuert die Aufnahme, sammelt die Daten der einzelnen Kameras und stellt diese zur Weiterverarbeitung zur Verfügung. Sie sendet eingehende Aufträge als Broadcast-Nachrichten in das Netzwerk an die Raspberry Pi Zero W mit den Kameras, die dann beispielsweise Bilder aufnehmen. Hierdurch wird die nahezu zeitgleiche Auslösung gewährleistet (\autoref{e:zeitgleich}), die bei einer einzelnen Ansteuerung als Schleife nicht möglich wäre. Zur Vereinheitlichung der Belichtung kann eine Funktion aktiviert werden, so dass erst einmal die Belichtung von jeder Kamera berechnet und diese dann von der \texttt{Control}-Klasse gemittelt wird. Dadurch werden dann alle Bilder mit der gleichen Einstellung aufgenommen, so dass keine Helligkeitsunterschiede zwischen den Aufnahmen bestehen (\autoref{e:licht}).
Nach der Aufnahme der Bilder und der Erkennung der ArUco-Marker werden die Daten von den Raspberry Pi Zero W an den Raspberry Pi 4 übertragen. Aus den ArUco-Markern wird die äußere Orientierung der Kameras als Näherungswerte bestimmt (\autoref{e:passpunkte}). Die Daten werden anschließend in einem Archiv gespeichert (\autoref{e:intspeicher}).

Die Datenübertragung an die Desktop-Software erfolgt über die REST-Schnittstelle, die wieder vom \texttt{Master}-Skript bereitgestellt wird. Alternativ kann auch ein USB-Stick an dem Raspberry Pi angesteckt werden (\autoref{e:usbspeicher}) oder die Daten über die Weboberfläche manuell heruntergeladen werden. Dazu wird bei der Verarbeitung der Daten geprüft, ob ein USB-Stick angeschlossen ist. Falls dieses der Fall ist, wird dieser gemountet, die Daten kopiert und der Stick wieder ausgehängt, damit dieser (fast) jederzeit getrennt werden kann. Das Datenformat auf dem USB-Stick und in den Archiv-Dateien aus der Weboberfläche entspricht dem, welches die Desktop-Software anlegt. So kann diese die Daten dann auch einladen und weiterverarbeiten.

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{./img/uml/uml_master_classdiagramm.pdf}
  \caption{Klassen des Master-Package} %Bildunterschrift
  \label{img:master} %ID fürs Bild
\end{figure}


\subsubsection{Kamera-Steuerung}
Die Raspberry Pi Zero W übernehmen die Steuerung der Kameras. Hierfür wurde ein Modul entwickelt, dass die Kameras steuert, die Bilder aufnimmt und anschließend dem steuernden Raspberry zur Verfügung stellt. Die Klassen sind in \autoref{img:uml_camera} dargestellt. Neben einer einfachen Benutzeroberfläche in Form einer über Flask bereitgestellten Website, erfolgt die Kommunikation bzw. Steuerung über eine REST-Schnittstelle zur Datenübertragung und eine Socket-Verbindung, die auf Broadcast-Nachrichten vom steuernden Raspberry Pi 4 wartet. Außerdem übernimmt der Raspberry Pi Zero W die Identifizierung von ArUco-Markern in den aufgenommenen Bildern (\autoref{e:passpunkte}).

\todo{mehr Details}

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{./img/uml/uml_camera_classdiagramm.pdf}
  \caption{Klassen des Camera-Package} %Bildunterschrift
  \label{img:uml_camera} %ID fürs Bild
\end{figure}


\subsection{Desktop-Schnittstelle (Java)}
Die Desktop-Schnittstelle dient zur Steuerung des Systems und zur automatischen Über\-tragung der Daten an die SfM-Software (\autoref{e:sfmsoftware}). Die Klassen sind in \autoref{img:uml_connector} dargestellt. Sie wurden in Java geschrieben, um eine einfache Installation auf verschiedenen Betriebssystemen zu ermöglichen. Die Kommunikation erfolgt über eine Socket-Verbindung zum Raspberry Pi 4. Neben der Übertragung der Bilder an die SfM-Software ermöglicht die Software das Starten von Aufnahmen. Ein Screenshot der Benutzeroberfläche ist in \autoref{img:screenshot_connector} dargestellt. Die Schnittstellen-Software unterstützt als SfM-Software aktuell Agisoft Metashape und OpenDroneMap, jedoch ist die Schnittstelle so gestaltet, dass auch andere Software ergänzt werden könnte.

\todo{mehr Details}

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{./img/connector_screenshot.png}
  \caption{Screenshot der Connector-Software unter Ubuntu 24.04} %Bildunterschrift
  \label{img:screenshot_connector} %ID fürs Bild
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{./img/uml/uml_connector_classdiagramm.pdf}
  \caption{Connector-Package} %Bildunterschrift
  \label{img:uml_connector} %ID fürs Bild
\end{figure}

\biblio
\end{document}